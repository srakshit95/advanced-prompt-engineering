{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c9082bd-b50d-4ea9-b500-9c5e71da546d",
   "metadata": {},
   "source": [
    "# We have modified the code file to correct a few errors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff472513",
   "metadata": {},
   "source": [
    "### Self Consistency Prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8a298f",
   "metadata": {},
   "source": [
    "Self consistency is a smarter way for LLMs to solve complex problems by exploring many different reasoning paths and then choosing the most common solution, significantly improving their problem-solving abilities. Through extensive testing on various challenging questions, the method proved to be highly effective, marking a big step forward in how LLMs understand and tackle complex tasks. You can more details about this prompting technique here - https://visualsummary.substack.com/p/self-consistency-prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f42dc64",
   "metadata": {},
   "source": [
    "### Loading libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7c0d45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os: Operating system interactions (file/directory manipulation).\n",
    "import os\n",
    "\n",
    "# operator.itemgetter: Extracts items from sequences.\n",
    "from operator import itemgetter\n",
    "\n",
    "# langchain_openai.ChatOpenAI: Integration with OpenAI's chat models for text generation.\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# langchain.prompts.PromptTemplate: Predefined templates for generating prompts.\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# langchain.schema.StrOutputParser: Parses string outputs into structured data.\n",
    "from langchain.schema import StrOutputParser\n",
    "\n",
    "# langchain.schema.runnable.RunnablePassthrough: Wraps runnable objects for easier execution.\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "\n",
    "# IPython.display: Displays output in Jupyter notebooks, including Markdown.\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4836b870",
   "metadata": {},
   "source": [
    "### Setting OpenAI API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06d2ba50",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = open('key.txt','r').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1977b74-33b2-4319-bc05-8a0756ee163c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c28595b3-7f21-4cd3-ae2b-799b0e9521da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv('/.env')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff35f6a",
   "metadata": {},
   "source": [
    "### Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c7d906a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a question about apple quantities and usage.\n",
    "question = \"\"\"The cafeteria had 23 apples. If they used 20 to make lunch and bought 6 more, how many apples do they have?\"\"\"\n",
    "\n",
    "# Provide context for answering questions, emphasizing detailed math and reasoning.\n",
    "context = \"\"\"Answer questions showing the full math and reasoning. Follow the pattern in the example.\"\"\"\n",
    "\n",
    "# Example problem-solving scenario involving arithmetic calculations.\n",
    "one_shot_example = \"\"\"Example \n",
    "Q: Roger has 5 tennis balls. He buys 2 more cans of tennis balls. Each can has 3 tennis balls. How many tennis balls does he \n",
    "have now? \n",
    "\n",
    "A: Roger started with 5 balls. 2 cans of 3 tennis balls each is 6 tennis balls. 5 + 6 = 11. The answer is 11.\n",
    "\n",
    "Q: \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42d9f7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a structured response using PromptTemplate, ChatOpenAI, and StrOutputParser.\n",
    "answer_1 = (\n",
    "    \n",
    "    # Start with a base response template followed by \"A: \".\n",
    "    PromptTemplate.from_template(context + one_shot_example + \" {input}\")\n",
    "    \n",
    "    # Use ChatOpenAI with temperature set to 0 for deterministic output.\n",
    "    | ChatOpenAI(temperature=0)\n",
    "    \n",
    "    # Parse the generated text into structured data.\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54dc1f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a structured response using PromptTemplate, ChatOpenAI, and StrOutputParser.\n",
    "answer_2 = (\n",
    "    \n",
    "    # Start with a base response template followed by \"A: \".\n",
    "    PromptTemplate.from_template(context + one_shot_example + \" {input}\")\n",
    "    \n",
    "    # Use ChatOpenAI with temperature set to 0 for deterministic output.\n",
    "    | ChatOpenAI(temperature=0.1)\n",
    "    \n",
    "    # Parse the generated text into structured data.\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dcb3f089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a structured response using PromptTemplate, ChatOpenAI, and StrOutputParser.\n",
    "answer_3 = (\n",
    "    \n",
    "    # Start with a base response template followed by \"A: \".\n",
    "    PromptTemplate.from_template(context + one_shot_example + \" {input}\")\n",
    "    \n",
    "    # Use ChatOpenAI with temperature set to 0 for deterministic output.\n",
    "    | ChatOpenAI(temperature=0.7)\n",
    "    \n",
    "    # Parse the generated text into structured data.\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f0c7ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final responder setup for formatting and displaying results in markdown.\n",
    "final_responder = (\n",
    "    \n",
    "    # Template for outputting results in markdown format.\n",
    "    PromptTemplate.from_template(\n",
    "        \"\"\"Output all the final results in this markdown format: Result 1: {results_1} \\n Result 2:{results_2} \\n Result 3: \n",
    "        {results_3}\"\"\"\n",
    "    )\n",
    "    \n",
    "    # Process the template through ChatOpenAI for text generation.\n",
    "    | ChatOpenAI()\n",
    "    \n",
    "    # Parse the generated text into structured data.\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a305d899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain together components for a comprehensive response process.\n",
    "chain = (\n",
    "    \n",
    "    # Map each answer to specific variables.\n",
    "     {\n",
    "        \"results_1\": answer_1,\n",
    "        \"results_2\": answer_2,\n",
    "        \"results_3\": answer_3,\n",
    "    }\n",
    "    \n",
    "    # Finalize the response with formatting and display.\n",
    "    | final_responder\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84c79065-a080-4745-8475-db7c3db95f2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "- Result 1: \n",
       "    A: The cafeteria started with 23 apples. They used 20 apples for lunch, leaving 3 apples. They then bought 6 more apples. 3 + 6 = 9. The cafeteria now has 9 apples. \n",
       "\n",
       "- Result 2: \n",
       "    A: The cafeteria started with 23 apples. They used 20 apples for lunch, leaving 23 - 20 = 3 apples. Then they bought 6 more apples, making a total of 3 + 6 = 9 apples. The answer is 9. \n",
       "\n",
       "- Result 3: \n",
       "    A: The cafeteria started with 23 apples. They used 20 for lunch, so they had 23 - 20 = 3 apples left. Then they bought 6 more apples, so they have 3 + 6 = 9 apples now. The answer is 9."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Invoke the response chain with a given input question.\n",
    "answers = chain.invoke({\"input\": question})\n",
    "\n",
    "# Display the generated answers in Markdown format.\n",
    "display(Markdown(answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "82f5a8fe-cf0e-4c28-84f4-79a114da736c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['input'], template='Answer questions showing the full math and reasoning. Follow the pattern in the example.Example \\nQ: Roger has 5 tennis balls. He buys 2 more cans of tennis balls. Each can has 3 tennis balls. How many tennis balls does he \\nhave now? \\n\\nA: Roger started with 5 balls. 2 cans of 3 tennis balls each is 6 tennis balls. 5 + 6 = 11. The answer is 11.\\n\\nQ:  {input}')\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x7e8464c50750>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7e8464c3db90>, temperature=0.0, openai_api_key=SecretStr('**********'), openai_proxy='')\n",
       "| StrOutputParser()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
