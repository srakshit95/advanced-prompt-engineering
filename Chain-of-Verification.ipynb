{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b47dc2d",
   "metadata": {},
   "source": [
    "### Chain-of-Verification Prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b460156c",
   "metadata": {},
   "source": [
    "This prompting technique helps LLMs not to make mistakes by checking their work with questions and answers before giving a final answer. This approach shows that the LLMs can be more accurate and make fewer errors when answering different types of questions or creating long pieces of text. You can find more details here - https://visualsummary.substack.com/p/chain-of-verification-prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d06857",
   "metadata": {},
   "source": [
    "This notebook is inspired from the below two resources - \n",
    "- https://github.com/ritun16/chain-of-verification\n",
    "- https://github.com/hwchase17/chain-of-verification/tree/master"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e899ad4e",
   "metadata": {},
   "source": [
    "### Loading libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d694efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the os module for interacting with the operating system\n",
    "import os\n",
    "\n",
    "# Import prompts\n",
    "from prompts import *\n",
    "\n",
    "# Importing ChatOpenAI model from langchain_openai for AI chat functionalities\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Importing PromptTemplate from langchain.prompts for creating prompt templates\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Importing ChatPromptTemplate from langchain.prompts for creating chat-specific prompt templates\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# Importing StrOutputParser from langchain.schema.output_parser for parsing string outputs\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "\n",
    "# Importing RunnablePassthrough for defining runnable objects that pass through inputs and outputs unchanged\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "\n",
    "# Importing RunnableLambda from langchain.schema.runnable for defining runnable objects that execute lambda functions\n",
    "from langchain.schema.runnable import RunnableLambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85565bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ff2697",
   "metadata": {},
   "source": [
    "### Setting up LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7777b73d-6e7d-44bd-a3c9-2b9955b030d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b8c68de-1f63-4717-94bb-daba01768778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv('/home/santhosh/Projects/courses/Pinnacle/.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02c2e545",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = open('key.txt','r').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef1b599f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up LLM to user\n",
    "llm = ChatOpenAI(model='gpt-4o-mini', temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2966f386",
   "metadata": {},
   "source": [
    "### Implementing Chain-of-Verification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6142199",
   "metadata": {},
   "source": [
    "![title](chain-of-verification.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d038574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain to generate initial answer\n",
    "baseline_response_prompt_template = PromptTemplate.from_template(BASELINE_PROMPT_WIKI)\n",
    "baseline_response_chain = baseline_response_prompt_template | llm | StrOutputParser()\n",
    "\n",
    "# Chain to generate a question template for verification answers\n",
    "verification_question_template_prompt_template = PromptTemplate.from_template(VERIFICATION_QUESTION_TEMPLATE_PROMPT_WIKI)\n",
    "verification_question_template_chain = verification_question_template_prompt_template | llm | StrOutputParser()\n",
    "\n",
    "# Chain to generate the verification questionts\n",
    "verification_question_generation_prompt_template = PromptTemplate.from_template(VERIFICATION_QUESTION_PROMPT_WIKI)\n",
    "verification_question_generation_chain = verification_question_generation_prompt_template | llm | StrOutputParser()\n",
    "\n",
    "# Chain to execute the verification\n",
    "execution_prompt_self_llm = PromptTemplate.from_template(EXECUTE_PLAN_PROMPT_SELF_LLM)\n",
    "execution_prompt_llm_chain = execution_prompt_self_llm | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ecf2937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a verification chain that splits verification questions into individual lines, \n",
    "# processes them through an execution chain, \n",
    "# and formats the final response\n",
    "\n",
    "verification_chain = RunnablePassthrough.assign(\n",
    "    split_questions=lambda x: x['verification_questions'].split(\"\\n\"),\n",
    ") | RunnablePassthrough.assign(\n",
    "    answers = (lambda x: [{\"verification_question\": q} for q in x['split_questions']])| execution_prompt_llm_chain.map()\n",
    ") | (lambda x: \"\\n\".join([\"Question: {} Answer: {}\\n\".format(question, answer) for question, answer in zip(x['split_questions'],\n",
    "                                                                                                           x['answers'])]))\n",
    "\n",
    "# Setting up a chain to generate the final answer using a refined prompt template, processed through LLM and output parsing\n",
    "final_answer_prompt_template = PromptTemplate.from_template(FINAL_REFINED_PROMPT)\n",
    "final_answer_chain = final_answer_prompt_template | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "545e84bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assembling a chain that integrates various components:\n",
    "# 1. Baseline response generation using a predefined chain\n",
    "# 2. Verification question template creation via a dedicated chain\n",
    "# 3. Generation of verification questions through another specialized chain\n",
    "# 4. Processing verification answers within a verification chain\n",
    "# 5. Finalizing the answer generation process with a final answer chain\n",
    "\n",
    "chain = RunnablePassthrough.assign(\n",
    "    baseline_response=baseline_response_chain\n",
    ") | RunnablePassthrough.assign(\n",
    "    verification_question_template=verification_question_template_chain\n",
    ") | RunnablePassthrough.assign(\n",
    "    verification_questions=verification_question_generation_chain\n",
    ") | RunnablePassthrough.assign(\n",
    "    verification_answers=verification_chain\n",
    ") | RunnablePassthrough.assign(\n",
    "    final_answer=final_answer_chain\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3320f610",
   "metadata": {},
   "source": [
    "### Response generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "824a98d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.invoke({\"original_question\": \"Is Narendra Modi born in Delhi?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f3d05c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Narendra Modi born in Delhi?\n"
     ]
    }
   ],
   "source": [
    "print(response['original_question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "393d0a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Narendra Modi\n",
      "2. Delhi\n"
     ]
    }
   ],
   "source": [
    "print(response['baseline_response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e07970fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Was Narendra Modi born in Delhi?\n"
     ]
    }
   ],
   "source": [
    "print(response['verification_question_template'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ed76fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Was Narendra Modi born in Delhi?\n"
     ]
    }
   ],
   "source": [
    "print(response['verification_questions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "173b8d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: 1. Was Narendra Modi born in Delhi? Answer: No, Narendra Modi was not born in Delhi. He was born on September 17, 1950, in Vadnagar, a town in the state of Gujarat, India.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(response['verification_answers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "08d68e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Refined Answer: No, Narendra Modi was not born in Delhi. He was born on September 17, 1950, in Vadnagar, a town in the state of Gujarat, India.\n"
     ]
    }
   ],
   "source": [
    "print(response['final_answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845635d9-f544-41eb-af93-244efa61fe6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
